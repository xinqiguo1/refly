import { SkillRunnableConfig } from '../../base';
import { checkHasContext, countToken, countMessagesTokens } from './token';
import { isEmptyMessage } from './truncator';
import { QueryProcessorResult } from '../types';
import { DEFAULT_MODEL_CONTEXT_LIMIT } from './constants';

export async function processQuery(
  query: string,
  config: SkillRunnableConfig,
): Promise<QueryProcessorResult> {
  const { modelConfigMap, chatHistory: rawChatHistory = [], context } = config.configurable;
  const modelInfo = modelConfigMap.queryAnalysis;

  // Process chat history - only filter empty messages
  // Note: Message truncation is handled by compressAgentLoopMessages which preserves tool_use/tool_result pairs
  const chatHistory = rawChatHistory.filter((message) => !isEmptyMessage(message));
  const usedChatHistory = chatHistory;

  // Check context
  const hasContext = checkHasContext(context);

  // Calculate tokens
  const maxTokens = modelInfo.contextLimit || DEFAULT_MODEL_CONTEXT_LIMIT;
  const queryTokens = countToken(query);
  const chatHistoryTokens = countMessagesTokens(usedChatHistory);
  const remainingTokens = maxTokens - queryTokens - chatHistoryTokens;

  const mentionedContext = {};

  return {
    optimizedQuery: query,
    query,
    usedChatHistory,
    hasContext,
    remainingTokens,
    mentionedContext,
  };
}
